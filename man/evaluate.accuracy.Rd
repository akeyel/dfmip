% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/dfmip.R
\name{evaluate.accuracy}
\alias{evaluate.accuracy}
\title{Evaluate accuracy}
\usage{
evaluate.accuracy(models.to.run, forecast.distributions, forecast.targets,
  observations.df, n.draws, threshold = "default",
  percentage = "default")
}
\arguments{
\item{models.to.run}{See \code{\link{dfmip.forecast}}}

\item{forecast.distributions}{See return object 2 in \code{\link{dfmip.forecast}}}

\item{forecast.targets}{See \code{\link{dfmip.forecast}}}

\item{observations.df}{A data frame with five fields: district, year, district_year, forecast.target, and value.
Value contains the observed value for the district and year for the corresponding forecast.target}

\item{n.draws}{See \code{\link{dfmip.forecast}}}

\item{threshold}{For continuous and discrete forecasts, a threshold of error to be used in classifying the forecast as "accurate". The default is +/- 1 human case, +/- 1 week, otherwise the default is 0.}

\item{percentage}{For continuous and discrete forecasts, if the prediction is within the specified percentage of the observed value, the forecast is considered accurate. The default is +/- 25 percent of the observed.}
}
\value{
accuracy.summary A data frame organized by model, district
(and an aggregation across all districts, currently denoted -STATEWIDE, but this does not have to be a state),
forecast.target, with entries for the following evaluation metrics: CRPS, RMSE, Scaled_RMSE, percentage, threshold,
percentage or threshold, and Area Under the Curve (AUC).
}
\description{
Evaluate accuracy
}
